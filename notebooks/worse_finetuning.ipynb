{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worse Fine Tuning\n",
    "\n",
    "Try to make BERT / RoBERTa worse by doing some additional pre-training on Wikipedia shuffled sentences.\n",
    "\n",
    "Based loosely off this tutorial: https://huggingface.co/blog/how-to-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "  AutoTokenizer,\n",
    "  AutoModelForMaskedLM,\n",
    "  DataCollatorForLanguageModeling,\n",
    "  Trainer,\n",
    "  TrainingArguments,\n",
    "  pipeline,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "# The GPU to use for training\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model\n",
    "\n",
    "To compare against corrupted model, try a simple fill-mask task with the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_mask = pipeline(\n",
    "  \"fill-mask\",\n",
    "  model=model,\n",
    "  tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'I have a book about animals.',\n",
       "  'score': 0.32578471302986145,\n",
       "  'token': 10529,\n",
       "  'token_str': 'have'},\n",
       " {'sequence': 'I had a book about animals.',\n",
       "  'score': 0.15185633301734924,\n",
       "  'token': 10374,\n",
       "  'token_str': 'had'},\n",
       " {'sequence': 'I wrote a book about animals.',\n",
       "  'score': 0.12935718894004822,\n",
       "  'token': 13954,\n",
       "  'token_str': 'wrote'},\n",
       " {'sequence': 'I did a book about animals.',\n",
       "  'score': 0.035083625465631485,\n",
       "  'token': 12172,\n",
       "  'token_str': 'did'},\n",
       " {'sequence': 'I write a book about animals.',\n",
       "  'score': 0.030550533905625343,\n",
       "  'token': 28685,\n",
       "  'token_str': 'write'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask(\"I [MASK] a book about animals.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct scrambled sentences from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9f6a421f604dcf8e455b822ff8b807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.93k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f38616a9d124380b1156cf1b8874e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikitext/wikitext-2-v1 (download: 4.27 MiB, generated: 12.72 MiB, post-processed: Unknown size, total: 16.99 MiB) to /Users/zhuzi/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01776200c1134d48b1263867b7e0b9e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikitext downloaded and prepared to /Users/zhuzi/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "wiki_dataset = load_dataset('wikitext', 'wikitext-2-v1', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(12345)\n",
    "scrambled_sentences = []\n",
    "for sent in wiki_dataset:\n",
    "  sent_toks = sent['text'].split()\n",
    "  random.shuffle(sent_toks)\n",
    "  scrambled_sentences.append(' '.join(sent_toks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShuffledWikiDataset(Dataset):\n",
    "  def __len__(self):\n",
    "    return len(scrambled_sentences)\n",
    "  def __getitem__(self, i):\n",
    "    return tokenizer(scrambled_sentences[i], max_length=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do more pre-training to degrade model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This controls the amount of degradation.\n",
    "corrupt_training_steps = 200\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir='./checkpoints/',\n",
    "  per_device_train_batch_size=16,\n",
    "  max_steps=corrupt_training_steps,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "  tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "  model=model,\n",
    "  tokenizer=tokenizer,\n",
    "  data_collator=data_collator,\n",
    "  train_dataset=ShuffledWikiDataset(),\n",
    "  args=training_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mziningzhu\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">./checkpoints/</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ziningzhu/huggingface\" target=\"_blank\">https://wandb.ai/ziningzhu/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ziningzhu/huggingface/runs/24sukp4e\" target=\"_blank\">https://wandb.ai/ziningzhu/huggingface/runs/24sukp4e</a><br/>\n",
       "                Run data is saved locally in <code>/Users/zhuzi/Documents/Github/probing_dataset/notebooks_bai/wandb/run-20210922_225403-24sukp4e</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 2:47:15, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=4.498060913085937, metrics={'train_runtime': 10113.209, 'train_samples_per_second': 0.02, 'total_flos': 436177113376032.0, 'epoch': 0.09, 'init_mem_cpu_alloc_delta': 10190848, 'init_mem_cpu_peaked_delta': 16384, 'train_mem_cpu_alloc_delta': 2810331136, 'train_mem_cpu_peaked_delta': 3823091712})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try fill-mask on corrupted model\n",
    "\n",
    "As we expected, the predictions are still reasonable, but worse (eg: top prediction is the same but confidence score is a lot lower)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_mask = pipeline(\n",
    "  \"fill-mask\",\n",
    "  model=model,\n",
    "  tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'I wrote a book about animals.',\n",
       "  'score': 0.13334225118160248,\n",
       "  'token': 13954,\n",
       "  'token_str': 'wrote'},\n",
       " {'sequence': 'I, a book about animals.',\n",
       "  'score': 0.08559725433588028,\n",
       "  'token': 117,\n",
       "  'token_str': ','},\n",
       " {'sequence': 'I. a book about animals.',\n",
       "  'score': 0.0455552339553833,\n",
       "  'token': 119,\n",
       "  'token_str': '.'},\n",
       " {'sequence': 'I is a book about animals.',\n",
       "  'score': 0.028200369328260422,\n",
       "  'token': 10124,\n",
       "  'token_str': 'is'},\n",
       " {'sequence': 'I was a book about animals.',\n",
       "  'score': 0.02120114676654339,\n",
       "  'token': 10134,\n",
       "  'token_str': 'was'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask(\"I [MASK] a book about animals.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model to disk\n",
    "\n",
    "To load, do `AutoModelForMaskedLM.from_pretrained(model_path)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_pretrained(f\"checkpoints/{model_name}-corrupt-{corrupt_training_steps}-steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate corrupted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - how to evaluate a model downloaded from cluster?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
